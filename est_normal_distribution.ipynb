{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82d827eb",
   "metadata": {},
   "source": [
    "# Generate Trainning/Testing Data (normal distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7bdb538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4041e6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data = []\n",
    "matching_parameters = []\n",
    "MIN_N = 10e1\n",
    "MAX_N = 10e2\n",
    "MAX_MEAN = 10000\n",
    "MAX_SD = 1000\n",
    "\n",
    "for i in range(0,100):\n",
    "    n = np.random.randint(MIN_N, MAX_N)\n",
    "    mean = np.random.randint(0, MAX_MEAN)/100.0\n",
    "    sd = np.random.randint(0,MAX_SD)/100.0\n",
    "    values = np.random.normal(mean, sd, n)\n",
    "    sampled_data.append(values)\n",
    "    matching_parameters.append([mean, sd, n])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "44e7ff48",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 2., 0., 1., 0., 2., 0., 0., 0., 1.,\n",
       "        2., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2.,\n",
       "        0., 1., 0., 2., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 1., 2., 1., 1., 2., 1., 0., 2., 0., 1., 1., 0., 2., 1., 1.,\n",
       "        0., 1., 1., 2., 1., 3., 1., 1., 2., 0., 3., 1., 3., 0., 1., 0., 1.,\n",
       "        1., 3., 1., 1., 0., 0., 2., 2., 3., 1., 1., 0., 3., 2., 0., 2., 1.,\n",
       "        2., 1., 1., 2., 2., 2., 2., 0., 2., 0., 1., 2., 2., 2., 4., 1., 2.,\n",
       "        1., 2., 0., 3., 2., 0., 0., 2., 2., 0., 0., 1., 1., 1., 1., 3., 2.,\n",
       "        0., 3., 0., 3., 3., 1., 2., 1., 3., 2., 4., 3., 3., 2., 1., 2., 0.,\n",
       "        1., 0., 1., 2., 3., 2., 3., 2., 5., 5., 1., 1., 2., 1., 2., 1., 1.,\n",
       "        3., 1., 2., 2., 3., 1., 2., 5., 0., 3., 2., 1., 2., 2., 3., 3., 6.,\n",
       "        2., 1., 2., 3., 4., 3., 0., 1., 6., 1., 2., 0., 3., 3., 2., 3., 2.,\n",
       "        0., 2., 6., 1., 5., 2., 5., 6., 1., 2., 1., 1., 2., 3., 4., 1., 1.,\n",
       "        2., 0., 3., 7., 2., 3., 0., 4., 1., 4., 3., 4., 3., 0., 1., 2., 2.,\n",
       "        3., 3., 2., 2., 1., 3., 5., 1., 1., 0., 3., 1., 2., 0., 4., 3., 3.,\n",
       "        1., 2., 1., 4., 4., 2., 1., 1., 0., 3., 3., 3., 0., 2., 1., 3., 2.,\n",
       "        4., 6., 0., 4., 1., 2., 1., 4., 1., 5., 3., 0., 2., 3., 0., 0., 1.,\n",
       "        3., 2., 1., 4., 3., 2., 2., 0., 2., 2., 1., 0., 4., 4., 2., 3., 3.,\n",
       "        2., 0., 0., 1., 2., 0., 2., 1., 1., 3., 1., 1., 0., 0., 2., 2., 1.,\n",
       "        1., 2., 2., 1., 1., 2., 0., 0., 1., 1., 3., 2., 1., 2., 0., 1., 1.,\n",
       "        2., 2., 1., 2., 1., 2., 2., 3., 1., 0., 1., 0., 0., 2., 0., 0., 1.,\n",
       "        2., 2., 2., 2., 0., 1., 1., 1., 1., 0., 1., 1., 3., 1., 2., 2., 1.,\n",
       "        0., 1., 1., 1., 1., 0., 0., 1., 2., 1., 2., 2., 0., 2., 3., 0., 2.,\n",
       "        1., 0., 1., 0., 0., 1., 1., 0., 0., 2., 0., 0., 1., 0., 2., 0., 1.,\n",
       "        1., 1., 2., 0., 0., 2., 0., 1., 2., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 2., 1., 0., 0., 1., 0., 0., 0., 1., 1., 2., 0., 1., 0., 2.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " array([-7.16587440e+00, -7.12591754e+00, -7.08596067e+00, -7.04600381e+00,\n",
       "        -7.00604695e+00, -6.96609009e+00, -6.92613323e+00, -6.88617637e+00,\n",
       "        -6.84621950e+00, -6.80626264e+00, -6.76630578e+00, -6.72634892e+00,\n",
       "        -6.68639206e+00, -6.64643520e+00, -6.60647833e+00, -6.56652147e+00,\n",
       "        -6.52656461e+00, -6.48660775e+00, -6.44665089e+00, -6.40669403e+00,\n",
       "        -6.36673716e+00, -6.32678030e+00, -6.28682344e+00, -6.24686658e+00,\n",
       "        -6.20690972e+00, -6.16695286e+00, -6.12699599e+00, -6.08703913e+00,\n",
       "        -6.04708227e+00, -6.00712541e+00, -5.96716855e+00, -5.92721169e+00,\n",
       "        -5.88725482e+00, -5.84729796e+00, -5.80734110e+00, -5.76738424e+00,\n",
       "        -5.72742738e+00, -5.68747052e+00, -5.64751365e+00, -5.60755679e+00,\n",
       "        -5.56759993e+00, -5.52764307e+00, -5.48768621e+00, -5.44772935e+00,\n",
       "        -5.40777248e+00, -5.36781562e+00, -5.32785876e+00, -5.28790190e+00,\n",
       "        -5.24794504e+00, -5.20798818e+00, -5.16803131e+00, -5.12807445e+00,\n",
       "        -5.08811759e+00, -5.04816073e+00, -5.00820387e+00, -4.96824701e+00,\n",
       "        -4.92829014e+00, -4.88833328e+00, -4.84837642e+00, -4.80841956e+00,\n",
       "        -4.76846270e+00, -4.72850584e+00, -4.68854897e+00, -4.64859211e+00,\n",
       "        -4.60863525e+00, -4.56867839e+00, -4.52872153e+00, -4.48876467e+00,\n",
       "        -4.44880780e+00, -4.40885094e+00, -4.36889408e+00, -4.32893722e+00,\n",
       "        -4.28898036e+00, -4.24902350e+00, -4.20906663e+00, -4.16910977e+00,\n",
       "        -4.12915291e+00, -4.08919605e+00, -4.04923919e+00, -4.00928233e+00,\n",
       "        -3.96932546e+00, -3.92936860e+00, -3.88941174e+00, -3.84945488e+00,\n",
       "        -3.80949802e+00, -3.76954116e+00, -3.72958429e+00, -3.68962743e+00,\n",
       "        -3.64967057e+00, -3.60971371e+00, -3.56975685e+00, -3.52979999e+00,\n",
       "        -3.48984312e+00, -3.44988626e+00, -3.40992940e+00, -3.36997254e+00,\n",
       "        -3.33001568e+00, -3.29005882e+00, -3.25010195e+00, -3.21014509e+00,\n",
       "        -3.17018823e+00, -3.13023137e+00, -3.09027451e+00, -3.05031765e+00,\n",
       "        -3.01036078e+00, -2.97040392e+00, -2.93044706e+00, -2.89049020e+00,\n",
       "        -2.85053334e+00, -2.81057648e+00, -2.77061961e+00, -2.73066275e+00,\n",
       "        -2.69070589e+00, -2.65074903e+00, -2.61079217e+00, -2.57083531e+00,\n",
       "        -2.53087844e+00, -2.49092158e+00, -2.45096472e+00, -2.41100786e+00,\n",
       "        -2.37105100e+00, -2.33109414e+00, -2.29113727e+00, -2.25118041e+00,\n",
       "        -2.21122355e+00, -2.17126669e+00, -2.13130983e+00, -2.09135296e+00,\n",
       "        -2.05139610e+00, -2.01143924e+00, -1.97148238e+00, -1.93152552e+00,\n",
       "        -1.89156866e+00, -1.85161179e+00, -1.81165493e+00, -1.77169807e+00,\n",
       "        -1.73174121e+00, -1.69178435e+00, -1.65182749e+00, -1.61187062e+00,\n",
       "        -1.57191376e+00, -1.53195690e+00, -1.49200004e+00, -1.45204318e+00,\n",
       "        -1.41208632e+00, -1.37212945e+00, -1.33217259e+00, -1.29221573e+00,\n",
       "        -1.25225887e+00, -1.21230201e+00, -1.17234515e+00, -1.13238828e+00,\n",
       "        -1.09243142e+00, -1.05247456e+00, -1.01251770e+00, -9.72560838e-01,\n",
       "        -9.32603976e-01, -8.92647115e-01, -8.52690253e-01, -8.12733391e-01,\n",
       "        -7.72776530e-01, -7.32819668e-01, -6.92862806e-01, -6.52905945e-01,\n",
       "        -6.12949083e-01, -5.72992221e-01, -5.33035360e-01, -4.93078498e-01,\n",
       "        -4.53121636e-01, -4.13164775e-01, -3.73207913e-01, -3.33251051e-01,\n",
       "        -2.93294189e-01, -2.53337328e-01, -2.13380466e-01, -1.73423604e-01,\n",
       "        -1.33466743e-01, -9.35098811e-02, -5.35530194e-02, -1.35961577e-02,\n",
       "         2.63607039e-02,  6.63175656e-02,  1.06274427e-01,  1.46231289e-01,\n",
       "         1.86188151e-01,  2.26145012e-01,  2.66101874e-01,  3.06058736e-01,\n",
       "         3.46015597e-01,  3.85972459e-01,  4.25929321e-01,  4.65886182e-01,\n",
       "         5.05843044e-01,  5.45799906e-01,  5.85756767e-01,  6.25713629e-01,\n",
       "         6.65670491e-01,  7.05627352e-01,  7.45584214e-01,  7.85541076e-01,\n",
       "         8.25497938e-01,  8.65454799e-01,  9.05411661e-01,  9.45368523e-01,\n",
       "         9.85325384e-01,  1.02528225e+00,  1.06523911e+00,  1.10519597e+00,\n",
       "         1.14515283e+00,  1.18510969e+00,  1.22506655e+00,  1.26502342e+00,\n",
       "         1.30498028e+00,  1.34493714e+00,  1.38489400e+00,  1.42485086e+00,\n",
       "         1.46480772e+00,  1.50476459e+00,  1.54472145e+00,  1.58467831e+00,\n",
       "         1.62463517e+00,  1.66459203e+00,  1.70454889e+00,  1.74450576e+00,\n",
       "         1.78446262e+00,  1.82441948e+00,  1.86437634e+00,  1.90433320e+00,\n",
       "         1.94429006e+00,  1.98424693e+00,  2.02420379e+00,  2.06416065e+00,\n",
       "         2.10411751e+00,  2.14407437e+00,  2.18403123e+00,  2.22398810e+00,\n",
       "         2.26394496e+00,  2.30390182e+00,  2.34385868e+00,  2.38381554e+00,\n",
       "         2.42377240e+00,  2.46372927e+00,  2.50368613e+00,  2.54364299e+00,\n",
       "         2.58359985e+00,  2.62355671e+00,  2.66351357e+00,  2.70347044e+00,\n",
       "         2.74342730e+00,  2.78338416e+00,  2.82334102e+00,  2.86329788e+00,\n",
       "         2.90325474e+00,  2.94321161e+00,  2.98316847e+00,  3.02312533e+00,\n",
       "         3.06308219e+00,  3.10303905e+00,  3.14299591e+00,  3.18295278e+00,\n",
       "         3.22290964e+00,  3.26286650e+00,  3.30282336e+00,  3.34278022e+00,\n",
       "         3.38273708e+00,  3.42269395e+00,  3.46265081e+00,  3.50260767e+00,\n",
       "         3.54256453e+00,  3.58252139e+00,  3.62247825e+00,  3.66243512e+00,\n",
       "         3.70239198e+00,  3.74234884e+00,  3.78230570e+00,  3.82226256e+00,\n",
       "         3.86221943e+00,  3.90217629e+00,  3.94213315e+00,  3.98209001e+00,\n",
       "         4.02204687e+00,  4.06200373e+00,  4.10196060e+00,  4.14191746e+00,\n",
       "         4.18187432e+00,  4.22183118e+00,  4.26178804e+00,  4.30174490e+00,\n",
       "         4.34170177e+00,  4.38165863e+00,  4.42161549e+00,  4.46157235e+00,\n",
       "         4.50152921e+00,  4.54148607e+00,  4.58144294e+00,  4.62139980e+00,\n",
       "         4.66135666e+00,  4.70131352e+00,  4.74127038e+00,  4.78122724e+00,\n",
       "         4.82118411e+00,  4.86114097e+00,  4.90109783e+00,  4.94105469e+00,\n",
       "         4.98101155e+00,  5.02096841e+00,  5.06092528e+00,  5.10088214e+00,\n",
       "         5.14083900e+00,  5.18079586e+00,  5.22075272e+00,  5.26070958e+00,\n",
       "         5.30066645e+00,  5.34062331e+00,  5.38058017e+00,  5.42053703e+00,\n",
       "         5.46049389e+00,  5.50045075e+00,  5.54040762e+00,  5.58036448e+00,\n",
       "         5.62032134e+00,  5.66027820e+00,  5.70023506e+00,  5.74019192e+00,\n",
       "         5.78014879e+00,  5.82010565e+00,  5.86006251e+00,  5.90001937e+00,\n",
       "         5.93997623e+00,  5.97993309e+00,  6.01988996e+00,  6.05984682e+00,\n",
       "         6.09980368e+00,  6.13976054e+00,  6.17971740e+00,  6.21967426e+00,\n",
       "         6.25963113e+00,  6.29958799e+00,  6.33954485e+00,  6.37950171e+00,\n",
       "         6.41945857e+00,  6.45941543e+00,  6.49937230e+00,  6.53932916e+00,\n",
       "         6.57928602e+00,  6.61924288e+00,  6.65919974e+00,  6.69915660e+00,\n",
       "         6.73911347e+00,  6.77907033e+00,  6.81902719e+00,  6.85898405e+00,\n",
       "         6.89894091e+00,  6.93889777e+00,  6.97885464e+00,  7.01881150e+00,\n",
       "         7.05876836e+00,  7.09872522e+00,  7.13868208e+00,  7.17863894e+00,\n",
       "         7.21859581e+00,  7.25855267e+00,  7.29850953e+00,  7.33846639e+00,\n",
       "         7.37842325e+00,  7.41838011e+00,  7.45833698e+00,  7.49829384e+00,\n",
       "         7.53825070e+00,  7.57820756e+00,  7.61816442e+00,  7.65812128e+00,\n",
       "         7.69807815e+00,  7.73803501e+00,  7.77799187e+00,  7.81794873e+00,\n",
       "         7.85790559e+00,  7.89786245e+00,  7.93781932e+00,  7.97777618e+00,\n",
       "         8.01773304e+00,  8.05768990e+00,  8.09764676e+00,  8.13760362e+00,\n",
       "         8.17756049e+00,  8.21751735e+00,  8.25747421e+00,  8.29743107e+00,\n",
       "         8.33738793e+00,  8.37734479e+00,  8.41730166e+00,  8.45725852e+00,\n",
       "         8.49721538e+00,  8.53717224e+00,  8.57712910e+00,  8.61708596e+00,\n",
       "         8.65704283e+00,  8.69699969e+00,  8.73695655e+00,  8.77691341e+00,\n",
       "         8.81687027e+00,  8.85682713e+00,  8.89678400e+00,  8.93674086e+00,\n",
       "         8.97669772e+00,  9.01665458e+00,  9.05661144e+00,  9.09656830e+00,\n",
       "         9.13652517e+00,  9.17648203e+00,  9.21643889e+00,  9.25639575e+00,\n",
       "         9.29635261e+00,  9.33630947e+00,  9.37626634e+00,  9.41622320e+00,\n",
       "         9.45618006e+00,  9.49613692e+00,  9.53609378e+00,  9.57605064e+00,\n",
       "         9.61600751e+00,  9.65596437e+00,  9.69592123e+00,  9.73587809e+00,\n",
       "         9.77583495e+00,  9.81579182e+00,  9.85574868e+00,  9.89570554e+00,\n",
       "         9.93566240e+00,  9.97561926e+00,  1.00155761e+01,  1.00555330e+01,\n",
       "         1.00954898e+01,  1.01354467e+01,  1.01754036e+01,  1.02153604e+01,\n",
       "         1.02553173e+01,  1.02952742e+01,  1.03352310e+01,  1.03751879e+01,\n",
       "         1.04151447e+01,  1.04551016e+01,  1.04950585e+01,  1.05350153e+01,\n",
       "         1.05749722e+01,  1.06149290e+01,  1.06548859e+01,  1.06948428e+01,\n",
       "         1.07347996e+01,  1.07747565e+01,  1.08147134e+01,  1.08546702e+01,\n",
       "         1.08946271e+01,  1.09345839e+01,  1.09745408e+01,  1.10144977e+01,\n",
       "         1.10544545e+01,  1.10944114e+01,  1.11343683e+01,  1.11743251e+01,\n",
       "         1.12142820e+01,  1.12542388e+01,  1.12941957e+01,  1.13341526e+01,\n",
       "         1.13741094e+01,  1.14140663e+01,  1.14540231e+01,  1.14939800e+01,\n",
       "         1.15339369e+01,  1.15738937e+01,  1.16138506e+01,  1.16538075e+01,\n",
       "         1.16937643e+01,  1.17337212e+01,  1.17736780e+01,  1.18136349e+01,\n",
       "         1.18535918e+01,  1.18935486e+01,  1.19335055e+01,  1.19734623e+01,\n",
       "         1.20134192e+01,  1.20533761e+01,  1.20933329e+01,  1.21332898e+01,\n",
       "         1.21732467e+01,  1.22132035e+01,  1.22531604e+01,  1.22931172e+01,\n",
       "         1.23330741e+01,  1.23730310e+01,  1.24129878e+01,  1.24529447e+01,\n",
       "         1.24929015e+01,  1.25328584e+01,  1.25728153e+01,  1.26127721e+01,\n",
       "         1.26527290e+01,  1.26926859e+01,  1.27326427e+01,  1.27725996e+01,\n",
       "         1.28125564e+01,  1.28525133e+01,  1.28924702e+01,  1.29324270e+01,\n",
       "         1.29723839e+01,  1.30123407e+01,  1.30522976e+01,  1.30922545e+01,\n",
       "         1.31322113e+01,  1.31721682e+01,  1.32121251e+01,  1.32520819e+01,\n",
       "         1.32920388e+01,  1.33319956e+01,  1.33719525e+01,  1.34119094e+01,\n",
       "         1.34518662e+01,  1.34918231e+01,  1.35317800e+01,  1.35717368e+01,\n",
       "         1.36116937e+01,  1.36516505e+01,  1.36916074e+01,  1.37315643e+01,\n",
       "         1.37715211e+01,  1.38114780e+01,  1.38514348e+01,  1.38913917e+01,\n",
       "         1.39313486e+01,  1.39713054e+01,  1.40112623e+01,  1.40512192e+01,\n",
       "         1.40911760e+01,  1.41311329e+01,  1.41710897e+01,  1.42110466e+01,\n",
       "         1.42510035e+01,  1.42909603e+01,  1.43309172e+01,  1.43708740e+01,\n",
       "         1.44108309e+01,  1.44507878e+01,  1.44907446e+01,  1.45307015e+01,\n",
       "         1.45706584e+01,  1.46106152e+01,  1.46505721e+01,  1.46905289e+01,\n",
       "         1.47304858e+01,  1.47704427e+01,  1.48103995e+01,  1.48503564e+01,\n",
       "         1.48903132e+01,  1.49302701e+01,  1.49702270e+01,  1.50101838e+01,\n",
       "         1.50501407e+01,  1.50900976e+01,  1.51300544e+01,  1.51700113e+01,\n",
       "         1.52099681e+01,  1.52499250e+01,  1.52898819e+01,  1.53298387e+01,\n",
       "         1.53697956e+01,  1.54097524e+01,  1.54497093e+01,  1.54896662e+01,\n",
       "         1.55296230e+01,  1.55695799e+01,  1.56095368e+01,  1.56494936e+01,\n",
       "         1.56894505e+01,  1.57294073e+01,  1.57693642e+01,  1.58093211e+01,\n",
       "         1.58492779e+01,  1.58892348e+01,  1.59291917e+01,  1.59691485e+01,\n",
       "         1.60091054e+01,  1.60490622e+01,  1.60890191e+01,  1.61289760e+01,\n",
       "         1.61689328e+01,  1.62088897e+01,  1.62488465e+01,  1.62888034e+01,\n",
       "         1.63287603e+01,  1.63687171e+01,  1.64086740e+01,  1.64486309e+01,\n",
       "         1.64885877e+01,  1.65285446e+01,  1.65685014e+01,  1.66084583e+01,\n",
       "         1.66484152e+01,  1.66883720e+01,  1.67283289e+01,  1.67682857e+01,\n",
       "         1.68082426e+01,  1.68481995e+01,  1.68881563e+01,  1.69281132e+01,\n",
       "         1.69680701e+01,  1.70080269e+01,  1.70479838e+01,  1.70879406e+01,\n",
       "         1.71278975e+01,  1.71678544e+01,  1.72078112e+01,  1.72477681e+01,\n",
       "         1.72877249e+01,  1.73276818e+01,  1.73676387e+01,  1.74075955e+01,\n",
       "         1.74475524e+01,  1.74875093e+01,  1.75274661e+01,  1.75674230e+01,\n",
       "         1.76073798e+01,  1.76473367e+01,  1.76872936e+01,  1.77272504e+01,\n",
       "         1.77672073e+01,  1.78071642e+01,  1.78471210e+01,  1.78870779e+01,\n",
       "         1.79270347e+01,  1.79669916e+01,  1.80069485e+01,  1.80469053e+01,\n",
       "         1.80868622e+01,  1.81268190e+01,  1.81667759e+01,  1.82067328e+01,\n",
       "         1.82466896e+01,  1.82866465e+01,  1.83266034e+01,  1.83665602e+01,\n",
       "         1.84065171e+01,  1.84464739e+01,  1.84864308e+01,  1.85263877e+01,\n",
       "         1.85663445e+01,  1.86063014e+01,  1.86462582e+01,  1.86862151e+01,\n",
       "         1.87261720e+01,  1.87661288e+01,  1.88060857e+01,  1.88460426e+01,\n",
       "         1.88859994e+01,  1.89259563e+01,  1.89659131e+01,  1.90058700e+01]),\n",
       " <BarContainer object of 655 artists>)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sampled_data[0],matching_parameters[0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e1f787",
   "metadata": {},
   "source": [
    "## Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f07e3d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_stats = []\n",
    "for i in range(0,len(sampled_data)):\n",
    "    #take elementwise average of each sample distribution\n",
    "    summary = []        # will contain [average, n]\n",
    "    summary.append(np.sum(sampled_data[i])/matching_parameters[i][2])\n",
    "    summary.append(matching_parameters[i][2])\n",
    "    \n",
    "    #predict mean first, remove irrelevant parameters\n",
    "    matching_parameters[i].pop(1)\n",
    "    matching_parameters[i].pop(1)\n",
    "    summary_stats.append(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91a0425",
   "metadata": {},
   "source": [
    "## Split into test & train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9169ed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = np.array(summary_stats), np.array(matching_parameters)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "59347585",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "065ef391",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "  def __init__(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "    self.X = torch.from_numpy(X.astype(np.float32))\n",
    "    self.y = torch.from_numpy(y.astype(np.float32))\n",
    "    self.len = self.X.shape[0]\n",
    "    \n",
    "  def __getitem__(self, index: int) -> tuple:\n",
    "    return self.X[index], self.y[index]\n",
    "\n",
    "  def __len__(self) -> int:\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c6695bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Data(x_train, y_train)\n",
    "test_data = Data(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b7c4f0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 41.3671, 679.0000]), tensor([41.4600]))\n"
     ]
    }
   ],
   "source": [
    "print(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b56a6c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_workers = 4\n",
    "\n",
    "#load data\n",
    "train_loader = DataLoader(train_data, \n",
    "                         batch_size=batch_size, \n",
    "                         shuffle=True, \n",
    "                         num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c91c0b",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b4e12cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "  def __init__(self, input_dim: int, \n",
    "               hidden_dim: int, output_dim: int) -> None:\n",
    "    super(LinearRegression, self).__init__()\n",
    "    self.input_to_hidden = nn.Linear(input_dim, hidden_dim)\n",
    "    self.hidden_layer_1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "    self.hidden_layer_2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "    self.hidden_to_output = nn.Linear(hidden_dim, output_dim)\n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    x = self.input_to_hidden(x)\n",
    "    x = self.hidden_layer_1(x)\n",
    "    x = self.hidden_layer_2(x)\n",
    "    x = self.hidden_to_output(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d8e25f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x_train.shape[1]\n",
    "hidden_dim = 2\n",
    "model = LinearRegression(input_dim, hidden_dim, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e964a1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(\n",
      "  (input_to_hidden): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (hidden_layer_1): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (hidden_layer_2): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (hidden_to_output): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7592a773",
   "metadata": {},
   "source": [
    "## Loss function & Optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6cbe0fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4035a3b2",
   "metadata": {},
   "source": [
    "## Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "526609fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "torch_shm_manager at \"/Users/User/anaconda3/lib/python3.11/site-packages/torch/bin/torch_shm_manager\": could not generate a random directory for manager socket",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[152], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      3\u001b[0m     running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (inputs, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;66;03m#inputs, labels = data\u001b[39;00m\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;66;03m# forward propagation\u001b[39;00m\n\u001b[1;32m      7\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m      8\u001b[0m         loss \u001b[38;5;241m=\u001b[39m loss_func(outputs, labels)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:438\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_iterator()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:386\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1039\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1032\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1039\u001b[0m w\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Popen(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_context\u001b[38;5;241m.\u001b[39mget_context()\u001b[38;5;241m.\u001b[39mProcess\u001b[38;5;241m.\u001b[39m_Popen(process_obj)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/context.py:288\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(process_obj)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_launch(process_obj)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/popen_spawn_posix.py:47\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, fp)\n\u001b[0;32m---> 47\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(process_obj, fp)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, file, protocol)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[38;5;241m.\u001b[39mdump(obj)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/multiprocessing/reductions.py:417\u001b[0m, in \u001b[0;36mreduce_storage\u001b[0;34m(storage)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    414\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot pickle CUDA storage; try pickling a CUDA tensor instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    415\u001b[0m     )\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m get_sharing_strategy() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_system\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 417\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m storage\u001b[38;5;241m.\u001b[39m_share_filename_cpu_()\n\u001b[1;32m    418\u001b[0m     cache_key \u001b[38;5;241m=\u001b[39m metadata[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    419\u001b[0m     rebuild \u001b[38;5;241m=\u001b[39m rebuild_storage_filename\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/storage.py:297\u001b[0m, in \u001b[0;36m_share_memory_lock_protected.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# If we acquired the storage lock here and we're done working on it\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;66;03m# we can now release it and free the entry.\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m to_free \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;66;03m# Ensure that the cdata from the storage didn't change and only\u001b[39;00m\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;66;03m# the data_ptr did.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/storage.py:334\u001b[0m, in \u001b[0;36mUntypedStorage._share_filename_cpu_\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;129m@_share_memory_lock_protected\u001b[39m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_share_filename_cpu_\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_share_filename_cpu_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: torch_shm_manager at \"/Users/User/anaconda3/lib/python3.11/site-packages/torch/bin/torch_shm_manager\": could not generate a random directory for manager socket"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        #inputs, labels = data\n",
    "        # forward propagation\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        # set optimizer to zero grad\n",
    "        # to remove previous epoch gradients\n",
    "        optimizer.zero_grad()\n",
    "        # backward propagation\n",
    "        loss.backward()\n",
    "        # optimize\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "      # display statistics\n",
    "    if not ((epoch + 1) % (epochs // 10)):\n",
    "        print(f'Epochs:{epoch + 1:5d} | ' \\\n",
    "              f'Batches per epoch: {i + 1:3d} | ' \\\n",
    "              f'Loss: {running_loss / (i + 1):.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e67a1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b25be3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
